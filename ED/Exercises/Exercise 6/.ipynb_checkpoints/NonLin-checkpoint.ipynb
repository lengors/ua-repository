{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non- Linear models for Classification\n",
    "-[Different algorithms](#Different-algorithms#)\n",
    "  - Multilayer Neural Networks\n",
    "  - SVM (non-linear kernels)\n",
    "  - random forrest\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numeric\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# graphics\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.gridspec as gridspec \n",
    "#\n",
    "#Added version check for recent scikit-learn 0.18 checks\n",
    "from distutils.version import LooseVersion as Version\n",
    "from sklearn import __version__ as sklearn_version\n",
    "###########\n",
    "from numpy import linalg as LA\n",
    "\n",
    "####http://rasbt.github.io/mlxtend/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, resolution=0.02):\n",
    "# setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "    #plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "    np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "    # plot class samples\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],\n",
    "            alpha=0.8, c=cmap(idx),marker=markers[idx], label=cl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "Xtoy, ytoy = make_moons(n_samples=100, random_state=123)\n",
    "\n",
    "plt.scatter(Xtoy[ytoy == 0, 0], Xtoy[ytoy == 0, 1], color='red', marker='^', alpha=0.5)\n",
    "plt.scatter(Xtoy[ytoy == 1, 0], Xtoy[ytoy == 1, 1], color='blue', marker='o', alpha=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./figures/half_moon_1.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "mlp = MLPClassifier(activation='tanh', hidden_layer_sizes=(10,5),alpha=0.01, max_iter=5000)\n",
    "mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.fit(Xtoy,ytoy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_regions(Xtoy, ytoy, classifier=mlp)\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('the weights are \\n',mlp.coefs_)\n",
    "print('the bias \\n ', mlp.intercepts_)\n",
    "print('number of iterations \\n', mlp.n_iter_)\n",
    "print('output activation', mlp.out_activation_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "1. What is the configuration of the network?\n",
    "2. What are the activation functions?\n",
    "3. How many iterations were taken to learn the training set.\n",
    "4. Change the configuration of the network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm=SVC(C=1.0,kernel='rbf', max_iter=1000, tol=1e-05, verbose=0)\n",
    "svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm=svm.fit(Xtoy,ytoy)\n",
    "plot_decision_regions(Xtoy, ytoy, classifier=svm)\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('dual coef \\n', svm.dual_coef_)\n",
    "print ('support vectors \\n', svm.support_vectors_)\n",
    "print('index of support vectors \\n ', svm.support_)\n",
    "print ('bias', svm.intercept_)\n",
    "print('the classifier \\n', svm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "\n",
    "1. The variables printed  are related with the following decision rule\n",
    "$$\n",
    "g(\\mathbf{z})=\\sum \\limits_{i=1}^{K_s} \\lambda_i d_i\\boldsymbol{\\phi}^T(\\mathbf{x}_i) \\boldsymbol(\\phi(\\mathbf{z})+b\n",
    "$$\n",
    "explain how.\n",
    "2. Create a function that evaluates the decison rule for a new example $(-1,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(max_depth=3, min_samples_split=5,n_estimators=10, max_features='log2', oob_score=False)\n",
    "forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.fit(Xtoy,ytoy)\n",
    "plot_decision_regions(Xtoy, ytoy, classifier=forest)\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('out-of-bag \\n', forest.oob_score_)\n",
    "print('importance\\n',forest.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "1. Interpret the parameters used to initialize the classifier.\n",
    "2. How many decision tees has the classifier?\n",
    "3. Explain the geometry of the decision surface. \n",
    "4. Relate the \"feature_importance\" values with the created decision surface. \n",
    "5. There is a parameter called \"oob_score\" it is initialized as False.  What is the goal of such a parameter? Modify it to True and see the outcome.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question:\n",
    "\n",
    "Apply the previous algorithms to a new data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## The data set\n",
    "\n",
    "X=np.array([[1,2],[2,3],[3, 3],[4,5],[5,5],[1,0],[2,1],[3,1],[5,3],[6,5]])\n",
    "\n",
    "print(X.shape)\n",
    "y=np.array([0,0,0,1,1,1,0,0,1,1])\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.scatter(X[y==0, 0], X[y==0, 1], color='red', marker='^', alpha=0.8)\n",
    "plt.scatter(X[y == 1, 0], X[y == 1, 1], color='blue', marker='o', alpha=0.8)\n",
    "plt.grid()\n",
    "plt.xlim([-1, 7])\n",
    "plt.ylim([-1, 6])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
